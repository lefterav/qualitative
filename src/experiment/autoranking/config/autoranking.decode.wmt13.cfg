[DEFAULT]
repetitions = 1
iterations = 130
path = /share/taraxu/selection-mechanism/wmt13/



experiment = grid
mode = "production"

langpair = ["de-en"]

ties = [False]
include_references = [False]

#raw, clean
trainset_mode = ["annotated"]

training_sets = "/share/taraxu/data/jcml/jcml-latest/{trainset_mode}/wmt2008-{langpair}-jcml-rank.all.analyzed.f.jcml,/share/taraxu/data/jcml/jcml-latest/{trainset_mode}/wmt2010-{langpair}-jcml-rank.all.analyzed.f.jcml,/share/taraxu/data/jcml/jcml-latest/{trainset_mode}/wmt2011-combo-{langpair}-jcml-rank.all.analyzed.f.jcml,/share/taraxu/data/jcml/jcml-latest/{trainset_mode}/wmt2011-newstest-{langpair}-jcml-rank.all.analyzed.f.jcml"
test_set = "/share/taraxu/data/jcml/jcml-latest/clean/wmt2009-{langpair}-jcml-rank.all.analyzed.f.jcml"

class_name = ["rank"]
class_type = "d"



params_LogReg = "{'stepwise_lr':True}"

#succesful features from our WMT11 metric
attset_2_source = "lm_unk"
attset_2_target = "lm_unk,l_tokens_ratio,berkeley-n_ratio,parse-VP_ratio,berkley-loglikelihood_ratio"
attset_2_general = ""

#succesful features from our WMT11 metric with no ratios
attset_21_source = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_21_target = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_21_general = ""

#succesful features from our WMT11 metric with no ratios + NPs
attset_22_source = "lm_unk,l_tokens,berkeley-n,parse-VP,parse-NP,berkley-loglikelihood"
attset_22_target = "lm_unk,l_tokens,berkeley-n,parse-VP,parse-NP,berkley-loglikelihood"
attset_22_general = 

#succesful features from our WMT11 metric with no ratios + system
attset_23_source = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_23_target = "system,lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_23_general = 

#succesful features from our WMT11 metric with no ratios + pseudoMETEOR
attset_24_source = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_24_target = "cross-meteor_score,lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_24_general = 

#quest baseline+ours
attset_33_source = "parse-comma,parse-dot,lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_33_target = "q_1001_1,q_1002_1,q_1006_1,q_1009_1,q_1012_1,q_1015_1,q_1022_1,q_1036_1,q_1049_1,q_1050_1,q_1053_1,q_1054_1,q_1057_1,q_1058_1,parse-comma,parse-dot,cross-meteor_score,lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_33_general = 

#de-en, wmtall, highest absolute relieff, n=5 
attset_411_source =
attset_411_target = "q_1077_1,cross-bleu,q_1063_1,q_1062_1,q_1078_1"
attset_411_general =

#combine 43 with 24
attset_431_source = "berkley-loglikelihood,lm_unk,l_tokens,berkeley-n,parse-VP"
attset_431_target = "q_1062_1,q_1063_1,q_1026_1,q_1081_1,lm_prob,q_1049_1,cross-meteor_fragPenalty,cross-meteor_recall,cross-meteor_precision,lm_prob,q_1009_1,q_1010_1,q_1016_1,q_1057_1,q_1057_1,q_1012_1,q_1022_1,berkley-loglikelihood,berkeley-n_ratio,q_1036_1,lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_431_general =



#promisable features
attset_6_source = "lm_unk,l_tokens,berkeley-n,spelling_score,grammar_score,style_score,parse-dot,parse-comma,lt_errors,lt_DE_CASE,lt_BISSTRICH,lt_DE_AGREEMENT"
attset_6_target = "meteor_score,lm_unk,berkeley-n,l_tokens,spelling_score,grammar_score,style_score,parse-dot,parse-comma,lt_errors,lt_EN_QUOTES,lt_EN_UNPAIRED_BRACKETS,lt_COMMA_PARENTHESIS_WHITESPACE,lt_DID_BASEFORM,lt_THREE_NN,lt_HE_VERB_AGR,lt_UPPERCASE_SENTENCE_START,lt_WORD_REPEAT_RULE"
attset_6_general =

#promisable features without language checking
attset_61_source = "lm_unk,l_tokens,berkeley-n,spelling_score,grammar_score,style_score,parse-dot,parse-comma"
attset_61_target = "meteor_score,lm_unk,berkeley-n,l_tokens,spelling_score,grammar_score,style_score,parse-dot,parse-comma"
attset_61_general =

#promisable features + system
attset_7_source = "lm_unk,l_tokens,berkeley-n,spelling_score,grammar_score,style_score,parse-dot,parse-comma,lt_errors,lt_DE_CASE,lt_BISSTRICH,lt_DE_AGREEMENT"
attset_7_target = "system,meteor_score,lm_unk,berkeley-n,l_tokens,spelling_score,grammar_score,style_score,parse-dot,parse-comma,lt_errors,lt_EN_QUOTES,lt_EN_UNPAIRED_BRACKETS,lt_COMMA_PARENTHESIS_WHITESPACE,lt_DID_BASEFORM,lt_THREE_NN,lt_HE_VERB_AGR,lt_UPPERCASE_SENTENCE_START,lt_WORD_REPEAT_RULE"
attset_7_general = 

att = ["attset_22","attset_23","attset_24","attset_6","attset_7","attset_61"]

meta_attributes = "testset,judgement_id,langsrc,langtgt,judgement_id,id,tgt-1_score,tgt-2_score,document_id,judge_id,segment_id"
hidden_attributes = "tgt-1_berkeley-tree,tgt-2_berkeley-tree,src_berkeley-tree,rank_diff"
discrete_attributes = "tgt-1_system,tgt-2_system,src_reuse_status,src_terminologyAdmitted_status,src_total_status,src_spelling_status,src_style_status,src_grammar_status,src_terminology_status,src_resultStats_projectStatus,tgt-1_reuse_status,tgt-1_terminologyAdmitted_status,tgt-1_total_status,tgt-1_spelling_status,tgt-1_style_status,tgt-1_grammar_status,tgt-1_terminology_status,tgt-1_resultStats_projectStatus,tgt-2_reuse_status,tgt-2_terminologyAdmitted_status,tgt-2_total_status,tgt-2_spelling_status,tgt-2_style_status,tgt-2_grammar_status,tgt-2_terminology_status,tgt-2_resultStats_projectStatus" 
 

[autoranking_decode_wmt13_de_en]
iterations = 119
trained_classifier = "/share/taraxu/selection-mechanism/wmt13/sentenceranking/autoranking_wmt13_newfeatures1_de_en/class_nameranklangpairde-eninclude_references0.0ties0.0trainset_modeannotatedattattset_33classifierLogReg/classifier.clsf"
att = "attset_33"
test_set = "/share/taraxu/selection-mechanism/wmt13/metric/jcml/wmt13-de-en.all.analyzed.f.jcml"

[autoranking_decode_wmt13_de_en_24]
iterations = 119
trained_classifier = "/share/taraxu/selection-mechanism/wmt13/sentenceranking/autoranking_wmt13_newfeatures1_de_en/class_nameranklangpairde-eninclude_references0.0ties0.0trainset_modeannotatedattattset_24classifierLogReg/classifier.clsf"
att = "attset_24"
test_set = "/share/taraxu/selection-mechanism/wmt13/metric/jcml/wmt13-de-en.all.analyzed.f.jcml"


[autoranking_decode_wmt13_en_es]
iterations = 119
trained_classifier = "/share/taraxu/selection-mechanism/wmt13/sentenceranking/autoranking_wmt13_newfeatures1_en_es/class_nameranklangpairen-esinclude_references0.0ties0.0trainset_modeannotatedattattset_411classifierLibLinearLogReg/classifier.clsf"
att = "attset_411"
test_set = "/share/taraxu/selection-mechanism/wmt13/metric/jcml/wmt13-en-es.all.analyzed.f.jcml"

[autoranking_decode_wmt13_en_es_431]
iterations = 119
trained_classifier = "/share/taraxu/selection-mechanism/wmt13/sentenceranking/autoranking_wmt13_newfeatures1_en_es/classifierLibLinearLogReginclude_references0.0attattset_431class_nameranklangpairen-esties0.0trainset_modeannotated/classifier.clsf"
att = "attset_431"
test_set = "/share/taraxu/selection-mechanism/wmt13/metric/jcml/wmt13-en-es.all.analyzed.f.jcml"




[autoranking_test_wmt12]
trained_classifier = /share/taraxu/selection-mechanism/autoranking/autoranking_featuresets_2d/class_nameranklangpairde-eninclude_references0.0ties0.0trainset_modeannotatedattattset_24classifierLogReg/classifier.clsf
att=attset_24
