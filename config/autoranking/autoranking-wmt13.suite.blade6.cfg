[DEFAULT]
repetitions = 1
iterations = 130
path = /local/elav01/selection-mechanism/wmt13/sentenceranking/


experiment = grid
mode = "production"

langpair = ["de-en"]

ties = [False]
include_references = [False]

#raw, clean
trainset_mode = ["annotated"]

training_sets = "/share/taraxu/data/jcml/jcml-latest-ref/{trainset_mode}/wmt2012-newstest-{langpair}-rank.all.analyzed.f.jcml,/share/taraxu/data/jcml/jcml-latest-ref/{trainset_mode}/wmt2010-{langpair}-jcml-rank.all.analyzed.f.jcml,/share/taraxu/data/jcml/jcml-latest-ref/{trainset_mode}/wmt2011-combo-{langpair}-jcml-rank.all.analyzed.f.jcml,/share/taraxu/data/jcml/jcml-latest-ref/{trainset_mode}/wmt2011-newstest-{langpair}-jcml-rank.all.analyzed.f.jcml"
test_set = "/share/taraxu/data/jcml/jcml-latest-ref/clean/wmt2009-{langpair}-jcml-rank.all.analyzed.f.jcml"

class_name = ["rank"]
class_type = "d"

classifier = ["LogReg", "SVMEasy", "kNN", "Naive"]


params_LogReg = "{'stepwise_lr':True}"

attset_1_source = 
attset_1_target = 
attset_1_general = 

#succesful features from our WMT11 metric
attset_2_source = "lm_unk"
attset_2_target = "lm_unk,l_tokens_ratio,berkeley-n_ratio,parse-VP_ratio,berkley-loglikelihood_ratio"
attset_2_general = 

#succesful features from our WMT11 metric with no ratios
attset_21_source = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_21_target = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_21_general = 

#succesful features from our WMT11 metric with no ratios + pseudoMETEOR
attset_24_source = "lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_24_target = "cross-meteor_score,lm_unk,l_tokens,berkeley-n,parse-VP,berkley-loglikelihood"
attset_24_general = 

#promisable features
attset_6_source = "lm_unk,l_tokens,berkeley-n,parse-dot,parse-comma,lt_errors,lt_DE_CASE,lt_BISSTRICH,lt_DE_AGREEMENT"
attset_6_target = "cross-meteor_score,lm_unk,berkeley-n,l_tokens,parse-dot,parse-comma,lt_errors,lt_EN_QUOTES,lt_EN_UNPAIRED_BRACKETS,lt_COMMA_PARENTHESIS_WHITESPACE,lt_DID_BASEFORM,lt_THREE_NN,lt_HE_VERB_AGR,lt_UPPERCASE_SENTENCE_START,lt_WORD_REPEAT_RULE"
attset_6_general =

att = ["attset_1","attset_2","attset_21","attset_24","attset_6"]

meta_attributes = "testset,judgement_id,langsrc,langtgt,ps1_judgement_id,ps2_judgement_id,id,tgt-1_score,tgt-1_system,tgt-2_score,tgt-2_system,document_id,judge_id,segment_id"
hidden_attributes = "tgt-1_berkeley-tree,tgt-2_berkeley-tree,src_berkeley-tree,rank_diff,tgt-1_ref-lev,tgt-1_ref-meteor_score,tgt-1_ref-meteor_fragPenalty,tgt-1_ref-meteor_recall,tgt-1_ref-meteor_precision,tgt-1_ref-bleu,tgt-2_ref-lev,tgt-2_ref-meteor_score,tgt-2_ref-meteor_fragPenalty,tgt-2_ref-meteor_recall,tgt-2_ref-meteor_precision,tgt-2_ref-bleu"
discrete_attributes = "src_reuse_status,src_terminologyAdmitted_status,src_total_status,src_spelling_status,src_style_status,src_grammar_status,src_terminology_status,src_resultStats_projectStatus,tgt-1_reuse_status,tgt-1_terminologyAdmitted_status,tgt-1_total_status,tgt-1_spelling_status,tgt-1_style_status,tgt-1_grammar_status,tgt-1_terminology_status,tgt-1_resultStats_projectStatus,tgt-2_reuse_status,tgt-2_terminologyAdmitted_status,tgt-2_total_status,tgt-2_spelling_status,tgt-2_style_status,tgt-2_grammar_status,tgt-2_terminology_status,tgt-2_resultStats_projectStatus" 


[autoranking_wmt13_basic]
remove_infinite = False

[autoranking_wmt13_basic_en-es_testmode-annotated]
classifier = ["LogReg", "SVMEasy", "kNN", "Naive"]
langpair = ["en-es"]

[autoranking_wmt13_basic_nullimputation]
att = ["attset_1","attset_6","attset_2","attset_21","attset_24"]
classifier = ["LogReg", "SVMEasy"]
nullimputation = True
langpair = ["de-en","en-es"]

